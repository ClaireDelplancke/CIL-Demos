{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Copyright 2019 Science Technology Facilities Council\n",
    "# Copyright 2019 University of Manchester\n",
    "#\n",
    "# This work is part of the Core Imaging Library developed by Science Technology\t\n",
    "# Facilities Council and University of Manchester\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0.txt\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# \n",
    "#========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction intro\n",
    "## FBP, CGLS\n",
    "\n",
    "**The goal** of this notebook is to get familiar with main Framework concepts through basic filtered-back projection (FBP) and Conjugate Gradient Least Squares (CGLS) reconstructions.\n",
    "\n",
    "**Learning objectives**\n",
    "In the end of this session, participants will be able to:\n",
    "- translate output of a CT instrument into Framework objects\n",
    "- set-up basic FBP reconstruction\n",
    "- formulate CT reconstruction as an optimisation problem and solve it iteratively\n",
    "- visualise final and intermediate reconstruction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports \n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some utilities\n",
    "\n",
    "# imports\n",
    "from ccpi.framework import ImageData, ImageGeometry\n",
    "from ccpi.framework import AcquisitionData, AcquisitionGeometry\n",
    "from ccpi.astra.operators import AstraProjectorSimple \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# simulate 'ideal', i.e. noise-free, sino\n",
    "def get_ideal_sino(data, N, n_angles):\n",
    "    \n",
    "    # get ImageGeometry\n",
    "    ig = data.geometry\n",
    "\n",
    "    # Create AcquisitionGeometry\n",
    "    angles = np.linspace(0, np.pi, n_angles, dtype=np.float32)\n",
    "\n",
    "    ag = AcquisitionGeometry(geom_type = \"parallel\",\n",
    "                             dimension = \"2D\", \n",
    "                             angles = angles,\n",
    "                             pixel_num_h = N)\n",
    "\n",
    "    dev = \"cpu\"\n",
    "\n",
    "    Aop = AstraProjectorSimple(ig, ag, dev)    \n",
    "    sino = Aop.direct(data)\n",
    "    return sino.as_array()\n",
    "\n",
    "\n",
    "# simulate noisy projetion, flat and adrk field images\n",
    "def get_real_sino(data, N, n_angles, n_bit):\n",
    "    \n",
    "    # detector bit depth\n",
    "    n_levels = 2 ** n_bit - 1\n",
    "    I_0 = 0.9 * n_levels\n",
    "    \n",
    "    # center of rotation offset\n",
    "    cor_offset = 0\n",
    "    \n",
    "    # shift senter of rotation\n",
    "    sino = np.roll(get_ideal_sino(data, N, n_angles), cor_offset, axis = 1)\n",
    "    \n",
    "    # generate flat field image (i.e. imitate non-uniform pixel response)\n",
    "    flat = np.uint32(np.tile(np.round(I_0 - I_0 * 0.1 * np.random.rand(1, N)), (n_angles, 1)))\n",
    "    \n",
    "    # generate dark field image (i.e. imitate dark current)\n",
    "    dark = np.uint32(np.tile(np.round(I_0 * 0.05 * np.random.rand(1, N)), (n_angles, 1)))\n",
    "    \n",
    "    # add noise to flat field image\n",
    "    flat_noisy = np.random.poisson(flat)\n",
    "    \n",
    "    # add dark current\n",
    "    flat_noisy += dark\n",
    "    \n",
    "    # based on ideal sinogram, generate projection image and add noise \n",
    "    proj = np.uint32(flat * np.exp(-sino))\n",
    "    proj_noisy = np.random.poisson(proj)\n",
    "    \n",
    "    # add dark current\n",
    "    proj_noisy += dark\n",
    "    \n",
    "    proj_noisy = np.float32(np.clip(proj_noisy, 0, n_levels))\n",
    "    flat_noisy = np.float32(np.clip(flat_noisy, 0, n_levels))\n",
    "    dark = np.float32(np.clip(dark, 0, n_levels)) \n",
    "    \n",
    "    return proj_noisy, flat_noisy, dark\n",
    "\n",
    "\n",
    "def plotter2D(datacontainers, titles, fix_range=False, stretch_y=False):\n",
    "    '''plotter2D(datacontainers, titles, fix_range=False, stretch_y=False)\n",
    "    \n",
    "    plots 1 or more 2D plots in an (n x 2) matix\n",
    "    multiple datasets can be passed as a list\n",
    "    \n",
    "    Can take ImageData, AquistionData or numpy.ndarray as input\n",
    "    '''\n",
    "    if(isinstance(datacontainers, list)) is False:\n",
    "        datacontainers = [datacontainers]\n",
    "\n",
    "    if(isinstance(titles, list)) is False:\n",
    "        titles = [titles]\n",
    "    \n",
    "    nplots = len(datacontainers)\n",
    "    rows = int(round((nplots+0.5)/2.0))\n",
    "\n",
    "    fig, (ax) = plt.subplots(rows, 2,figsize=(15,15))\n",
    "\n",
    "    axes = ax.flatten() \n",
    "\n",
    "    range_min = float(\"inf\")\n",
    "    range_max = 0\n",
    "    \n",
    "    if fix_range == True:\n",
    "        for i in range(nplots):\n",
    "            if type(datacontainers[i]) is np.ndarray:\n",
    "                dc = datacontainers[i]\n",
    "            else:\n",
    "                dc = datacontainers[i].as_array()\n",
    "                \n",
    "            range_min = min(range_min, np.amin(dc))\n",
    "            range_max = max(range_max, np.amax(dc))\n",
    "        \n",
    "    for i in range(rows*2):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    for i in range(nplots):\n",
    "        axes[i].set_visible(True)\n",
    "        axes[i].set_title(titles[i])\n",
    "       \n",
    "        if type(datacontainers[i]) is np.ndarray:\n",
    "            dc = datacontainers[i]\n",
    "        else:\n",
    "            dc = datacontainers[i].as_array()    \n",
    "        \n",
    "        sp = axes[i].imshow(dc)\n",
    "        \n",
    "        im_ratio = dc.shape[0]/dc.shape[1]\n",
    "        \n",
    "        if stretch_y == True:   \n",
    "            axes[i].set_aspect(1/im_ratio)\n",
    "            im_ratio = 1\n",
    "        \n",
    "        plt.colorbar(sp, ax = axes[i],fraction = 0.0467 * im_ratio, pad = 0.02)\n",
    "        \n",
    "        if fix_range == True:\n",
    "            sp.set_clim(range_min,range_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT data acquisition\n",
    "\n",
    "In conventional CT systems, an object is placed between a source emitting X-rays and a detector array measuring the  X-ray transmission images of the incident X-rays. Typically, either the object is placed on a rotating sample stage and rotates with respect to the source-detector assembly, or the source-detector gantry rotates with respect to the stationary object.\n",
    "\n",
    "In the Framework, we implemented `AcquisitionGeometry` class to hold acquisition parameters and `ImageGeometry` to hold geometry of a reconstructed volume. Corresponding data arrays are wrapped as `AcquisitionData` and `ImageData` classes, respectively. In this notebook we will work with parallel geometry. More complex geometries will be discussed in the following notebooks. Geometrical parameters for parallel geometry are depicted below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/parallel_geometry.png\" width=600 height=600 align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Framework, we define parallel `AcquisitionGeometry` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ccpi.framework import AcquisitionGeometry\n",
    "import numpy as np\n",
    "\n",
    "# acquisition angles\n",
    "n_angles = 360\n",
    "angles = np.linspace(0, np.pi, n_angles, dtype = np.float32)\n",
    "\n",
    "# number of pixels in detector row\n",
    "N = 512\n",
    "\n",
    "# pixel size\n",
    "pixel_size_h = 1\n",
    "\n",
    "# # create AcquisitionGeometry\n",
    "ag = AcquisitionGeometry(geom_type = \"parallel\",\n",
    "                         dimension = \"2D\",\n",
    "                         angles = angles,\n",
    "                         pixel_num_h = N,\n",
    "                         pixel_size_h = pixel_size_h)\n",
    "\n",
    "print(\"Acquisition geometry:\\n{}\".format(ag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AcquisitionGeometry` contains only metadata, the actual data is wrapped in `AcquisitionData` class.`AcquisiitonGeometry` class also holds information about arrangement of the actual acquisition data array. We use attribute `dimension_labels` to label axis. The expected dimension labels are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/parallel_data.png\" width=300 height=300 align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default order of dimensions for `AcquisitionData` is `[angle, horizontal]`, meaning that the number of elements along 0 and 1 axes in the acquisition data array is expected to be `n_angles` and `N`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimension labels:\\n{}\".format(ag.dimension_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have consistent `AcquisitionData` and `AcquisitionGeometry`, we recommend to allocate `AcquisitionData` using `allocate` method of `AcquisitionGeometry` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ccpi.framework import AcquisitionData\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# allocate AcquisitionData\n",
    "ad = ag.allocate()\n",
    "\n",
    "print(\"Dimensions and Labels = {}, {}\".format(ad.shape, ad.dimension_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Framework provides a number of test images\n",
    "\n",
    "- BOAT = 'boat.tiff'\n",
    "- CAMERA = 'camera.png'\n",
    "- PEPPERS = 'peppers.tiff'\n",
    "- RESOLUTION_CHART = 'resolution_chart.tiff'\n",
    "- SIMPLE_PHANTOM_2D = 'hotdog'\n",
    "- SHAPES = 'shapes.png'\n",
    "    \n",
    "Here we load a 'hotdog' image (a simple CT phantom consisting of 2 materials) and generate a sinogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccpi.framework import TestData\n",
    "import os, sys\n",
    "\n",
    "# load test image\n",
    "# initialise loader\n",
    "loader = TestData(data_dir = os.path.join(sys.prefix, \"share\", \"ccpi\"))\n",
    "# load data\n",
    "data = loader.load(TestData.SIMPLE_PHANTOM_2D, size = (N, N))\n",
    "# scale data\n",
    "data *= 2.5 / N\n",
    "\n",
    "plotter2D([data],\n",
    "          [\"Ground truth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can pass actual sinogram to `AcquisitionData`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.fill(get_ideal_sino(data, N, n_angles))\n",
    "\n",
    "plotter2D([ad],\n",
    "          [\"noise-free sinogram\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT data preprocessing\n",
    "\n",
    "As X-ray photons travel from an X-ray source to detector elements they interact with matter along their trajectories. In these interactions, photons are either absorbed or scattered, resulting in the attenuation of the incident X-ray. A quantitative description of the interaction of X-rays with matter is given by the Beer-Lambert law (or Beer’s law).\n",
    "$$I^{l} = I^0 \\mathrm{exp}\\left( -\\int_{l} f(g) \\mathrm{d}l \\right)$$\n",
    "where $f(g)$ is the X-ray linear attenuation coefficient of the object at the position $g$ along a given linear X-ray trajectory $l$ from the source to the detector element. If $l$ is the entire trajectory from the source to the detector element, then $I^0$ corresponds to the X-ray intensity upon emission from the source and $I^{l}$ corresponds to the X-ray intensity upon incidence on the detector element. $I^{l}$ is typically called a transmission measurement, whereas a projection measurement is given by\n",
    "$$G^{l} = -\\log \\left( \\frac{I^{l}}{I^0} \\right) = \\int_{l} f(g) \\mathrm{d}l$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, $I^0$ is a single value, but real detector pixels do respond equally to photon flux. Secondly, pixels might have residual charge (so called dark current). Therefore, to convert $I^{l}$ to $G^{l}$, one needs to perform flat field correction. If $I^F$ is a flat field image (acquired with source on, without an object in the field of view) and $I^d$ is a dark field image (acquired with source off), then flat field correction is given by:\n",
    "$$\\frac{I-I^D}{I^F-I^D}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated noisy sinogram, flat and dark field images\n",
    "proj_tmp, flat_tmp, dark_tmp  = get_real_sino(data, N, n_angles, 8)\n",
    "\n",
    "plotter2D([proj_tmp, flat_tmp, dark_tmp], \n",
    "          [\"Projection\", \"Flat field\", \"dark field\"], \n",
    "          fix_range = True, \n",
    "          stretch_y = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_noisy = ag.allocate()\n",
    "proj_noisy.fill(proj_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap  flat and dark field images as AcquisitionData objects\n",
    "flat = ag.allocate()\n",
    "flat.fill(flat_tmp)\n",
    "dark = ag.allocate()\n",
    "dark.fill(dark_tmp)\n",
    "\n",
    "# and perform flat field correction and take negative logarithm\n",
    "ad_noisy = -1*(((proj_noisy - dark) / (flat - dark)).log())\n",
    "\n",
    "plotter2D([ad, ad_noisy], \n",
    "          [\"Noise-free sinogram\", \"Noisy sinogram\"], \n",
    "          fix_range = True, \n",
    "          stretch_y = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, we defined algebraic operations for `AcquisitionData` objects, i.e. you can manipulate them as `numpy` arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT reconstruction\n",
    "Tomographic reconstruction consists of resolving the three-dimensional photon attenuation map of a scanned object from the collection of projection measurement $G^{l}$. There are two major classes of reconstruction algorithms: *analytic* and *iterative*. \n",
    "\n",
    "### Analytic reconstruction\n",
    "The most common analytic reconstruction algorithm is filtered back-projection (FBP). The FBP algorithm is derived from the Fourier Slice theorem which relates line integral measurements to two dimensional Fourier transform of an object’s slice. Although the Fourier Slice theorem provides straightforward solution for tomographic reconstruction, its practical implementation is challenging due to required interpolation from Polar to Cartesian coordinates in the Fourier space. In FBP-type reconstruction methods, projections are ﬁltered independently and then back-projected onto the plane of the tomographic slice. Filtration is used to compensate for nonuniform sampling of the Fourier space (higher frequencies have higher density of sampling points) by linear (Ramp) weighting of the frequency space.\n",
    "\n",
    "To store reconstruction results, we implemented two classes: `ImageGeometry` and `ImageData`. Similar to `AcquisitionData` and `AcquisitionGeometry`, we first define 2D `ImageGeometry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ccpi.astra.processors import FBP\n",
    "\n",
    "# reconstruction settings\n",
    "dev = \"cpu\" # can be \"gpu\"\n",
    "\n",
    "# create ImageGeometry \n",
    "ig = ImageGeometry(voxel_num_x = ag.pixel_num_h,\n",
    "                   voxel_size_x = ag.pixel_size_h,\n",
    "                   voxel_num_y = ag.pixel_num_h,\n",
    "                   voxel_size_y = ag.pixel_size_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FBP algorithm is implemented as a `processor` which takes as an input `AcquisitionData` along with `AcquisitionGeometry` and `ImageGeometry`, and returns reconstructed `ImageData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct noise-free data\n",
    "# configure FBP\n",
    "fbp = FBP(volume_geometry = ig, \n",
    "          sinogram_geometry = ag,\n",
    "          device = dev)\n",
    "# pass actual AcquisitionData\n",
    "fbp.set_input(ad)\n",
    "# run FBP and get results\n",
    "recon_fbp_ideal = fbp.process()\n",
    "\n",
    "# reconstruct noisy data\n",
    "fbp.set_input(ad_noisy)\n",
    "recon_fbp_noisy = fbp.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter2D([data], \n",
    "          [\"Ground truth\"])\n",
    "\n",
    "plotter2D([recon_fbp_ideal, recon_fbp_noisy], \n",
    "          [\"Reconstruction of noise-free sinogram\", \"Reconstruction of noisy sinogram\"], \n",
    "          fix_range = False, \n",
    "          stretch_y = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ImageData` and `AcquisitionData` inherit from the same `DataContainer` class, consequently they behave the same way. For instance, we can subtract ground truth from the reconstruction results to visualise residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show residuals\n",
    "plotter2D([(recon_fbp_ideal - data), (recon_fbp_noisy - data)], \n",
    "          [\"Relative error, noise-free data\", \"Relative error, noisy data\"], \n",
    "          fix_range = False, \n",
    "          stretch_y = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise_1'></a>\n",
    "**Exercise 1**: use the following mask to simulate missing angles acquisition and perform reconstruction again for both noise-free and noisy data.\n",
    "\n",
    "New acquisition angles are now given by the following `mask`:\n",
    "```\n",
    "a = np.int32((np.arange(1,28) * np.arange(0,27)) / 4)\n",
    "mask = np.concatenate([a, n_angles - 1 - a[::-1]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.int32(np.round((np.arange(1,28) * np.arange(0,27)) / 4))\n",
    "mask = np.concatenate([a, n_angles - 1 - a[::-1]])\n",
    "\n",
    "# visualise new sinogram\n",
    "sino_masked = np.zeros_like(ad.as_array())\n",
    "sino_masked[mask, :] = ad.as_array()[mask, :]\n",
    "\n",
    "plotter2D([sino_masked],\n",
    "          [\"Missing angles sinogram\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint*: you do not need to generate sinograms again, you can create new `AcquisitionGeometry` and `AcquisitionData` using `numpy` slicing, for instance:\n",
    "```\n",
    "ad_low = ag_low.allocate()\n",
    "ad_low.fill(ad.as_array()[mask,:])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative reconstruction\n",
    "As you have seen in the exercise, FBP reconstruction fails to reconstruct the dataset with low number of projections. Alternatively, iterative reconstruction methods tend to have better perfomance for datasets with low number of projections and/ or missing angles.\n",
    "\n",
    "Iterative methods use an initial estimate of volume voxel values which is then iteratively updated to best reproduce acquired radiographic data. Here we discuss formulation of iterative reconstruction for 2D parallel gemetry, extension to other geometies is straightforward. Iterative methods formulate the reconstruction methods as a system of linear equations,\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "- $x$ is the volume to be reconstructed. $x$ is typically represented as a column vector with $N \\cdot N \\times 1$ elements, where $N$ is the number of elements in a detector row.\n",
    "- $b$ is measured data from $M$ measurements (projections), $b$ is a column vector with $N \\cdot M \\times 1$ elements\n",
    "- $A$ is the projection operator with $N \\cdot M \\times N \\cdot N$ elements. If $i, i = \\{0, 1, \\dots N \\cdot M - 1 \\}$ and $j, j = \\{0, 1, \\dots, N \\cdot N - 1\\}$, then $A_{i,j}$ is the length of intersection of the $i$.th ray with the $j$.th voxel.\n",
    "\n",
    "For any real application, problem size is too large to be solved by direct inversion methods, i.e.\n",
    "\n",
    "$$x = A^{-1}b$$\n",
    "\n",
    "Secondly, the projection matrix $A$ is often under-determined (low number of projections or missing angles), i.e. \n",
    "\n",
    "$$M \\ll N$$\n",
    "\n",
    "Therefore we formulate reconstruction as an optimization problem and use iterative solvers to solve:\n",
    "\n",
    "$$\\underset{x}{\\mathrm{argmin}}\\begin{Vmatrix}A x - b\\end{Vmatrix}^2_2$$\n",
    "\n",
    "Since iterative methods involve forward- and back-projection steps, assumptions of data acquisition, data processing, system geometries, and noise characteristic can be incorporated into the reconstruction procedure. However, iterative methods are computationally demanding, you will notice that it takes longer to get reconstruction results with iterative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From mathematical point of view, projection matrix $A$ is an operator which maps from the set $x$ (*domain*) to the set $b$ (*range*):\n",
    "$$A: x \\to b$$\n",
    "In the framework, we implemented a generic `operator` class. The two most important methods of the `operator` are `direct` and `adjoint` methods that describe the result of applying the operator, and its adjoint respectively, onto a compatible `DataContainer` (`AcquisitionData` or `ImageData`) input. The output is another `DataContainer` object or subclass hereof. An important special case of the `operator` class, is the projection operator for CT, where `direct` and `adjoint` method correspond to forward- and back-projection respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ccpi.astra.operators import AstraProjectorSimple \n",
    "\n",
    "# define the projection operator A\n",
    "device = \"cpu\" # or \"gpu\" if available\n",
    "operator = AstraProjectorSimple(ig, ag, device)\n",
    "\n",
    "# forward projection\n",
    "forward_projection = operator.direct(data)\n",
    "\n",
    "# back_projection\n",
    "back_projection = operator.adjoint(forward_projection)\n",
    "\n",
    "plotter2D([forward_projection, back_projection],\n",
    "          [\"Forward projection\", \"Back projection\"],\n",
    "          fix_range = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Range: {} \\n\".format(operator.range_geometry()))\n",
    "print(\"Domain: {} \\n\".format(operator.domain_geometry()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Operator norm: {}\\n\".format(operator.norm()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Framework provides a number of generic optimisation algorithms implementations. All algorithms share the same interface and behaviour. Algorithms are iterable Python object which can be run in a for loop. Can be stopped and warm restarted.\n",
    "\n",
    "The Conjugate Gradient Least Squares (CGLS) algorithm is commonly used for solving large systems of linear equations, due to its fast convergence. CGLS takes `operator`, measured data and initial value as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ccpi.optimisation.algorithms import CGLS\n",
    "\n",
    "# initial estimate - zero array in this case \n",
    "x_init = ig.allocate(0)\n",
    "\n",
    "# setup CGLS\n",
    "cgls = CGLS(x_init = x_init, \n",
    "            operator = operator, \n",
    "            data = ad)\n",
    "cgls.max_iteration = 10\n",
    "cgls.update_objective_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run N interations\n",
    "cgls.run(10, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and visusualise the results\n",
    "CGLS_res = cgls.get_output()\n",
    "\n",
    "plotter2D([CGLS_res, CGLS_res - data],\n",
    "          [\"CGLS reconstruction\", \"Difference from ground truth\"],\n",
    "          fix_range = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, tolerance can be used as a stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CGLS\n",
    "cgls = CGLS(x_init = x_init, \n",
    "            operator = operator, \n",
    "            data = ad,\n",
    "            tolerance = 1e-4) # default 1e-6\n",
    "cgls.max_iteration = 500\n",
    "cgls.update_objective_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run N interations\n",
    "cgls.run(200, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and visusualise the results\n",
    "CGLS_res = cgls.get_output()\n",
    "\n",
    "plotter2D([CGLS_res, CGLS_res - data],\n",
    "          [\"CGLS reconstruction\", \"Difference from ground truth\"],\n",
    "          fix_range = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CGLS without explicit regularization, the number of iterations plays the role of a regularisation parameter. However, it is often unclear how many iterations is required to get 'good' reconstruction. Let us reconstruct the noisy dataset and visualise intermediate reconstruction results to control quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 20\n",
    "step = 2\n",
    "\n",
    "# setup CGLS\n",
    "cgls = CGLS(x_init = x_init, \n",
    "            operator = operator, \n",
    "            data = ad_noisy)\n",
    "cgls.max_iteration = max_iter\n",
    "\n",
    "for i in range(0, max_iter // step):\n",
    "    cgls.run(step, verbose = True)\n",
    "    \n",
    "    # get and visusualise the results\n",
    "    CGLS_res = cgls.get_output()\n",
    "\n",
    "    plotter2D([CGLS_res, CGLS_res - data],\n",
    "              [\"Iteration {}, objective {}\".format(i * step, cgls.loss[-1]), \"Difference from ground truth\"],\n",
    "              fix_range = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that after iteration 4, reconstruction gets more noisy even though objective value keeps decreasing. After iteration 8, you cannot see any significant changes in the reconstruction result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: set-up CGLS reconstruction for low-projection datasets ([go to excercise 1](#exercise_1)). Try to find number of iterations for the noisy dataset which gives the most interpretable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you have learn how to:\n",
    "- create `AcquisitionGeometry` and `ImageGeometry`\n",
    "- manipulate `AcquisitionData` and `ImageData`\n",
    "- implement basic CT reconstructions, including analytic FBP and iterative CGLS reconstruction algorithms\n",
    "- evaluate intermediate and final reconstruction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
