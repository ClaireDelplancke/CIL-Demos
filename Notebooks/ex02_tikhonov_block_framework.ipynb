{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Copyright 2019 Science Technology Facilities Council\n",
    "# Copyright 2019 University of Manchester\n",
    "#\n",
    "# This work is part of the Core Imaging Library developed by Science Technology\t\n",
    "# Facilities Council and University of Manchester\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0.txt\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# \n",
    "#========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tikhonov regularisation using CGLS and block framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise introduces Tikhonov regularisation and explains how this is implemented in the CIL framework using the so-called block framework.\n",
    "\n",
    "In the previous exercise, it was seen how CGLS could be used to determine a reconstruction based on the least squares reconstruction problem. It was seen that in case of noisy data, the least squares solution obtained by running until convergence is not desirable due to a high amount of noise. The number of iterations was seen to have a regularising effect, with the smooth, low-frequency components of the image recovered in the first iterations, while high-frequency components of the image such as edges were recovered later. Unfortunately, noise also kicks in, and one needs to pick the number of iterations that best balances the sharpness and amount of noise. As such, the regularising effect is implicitly obtained by choosing the number of iterations to run and never actually running until converged to the least squares solution.\n",
    "\n",
    "Tikhonov regularization is more explicit in that a regularization term is added to the least squares fitting term, specifically a squared 2-norm. This problem should now be solved to convergence instead of using the number of iterations as implicit regularising effect. Instead, a parameter, the regularization parameter, balances the emphasis on fitting the data and enforcing the regularity and must be chosen to provide the best trade-off.\n",
    "\n",
    "Tikhonov regularization tends to offer reduction of noise in the reconstruction, at the price of some blurring. This will be seen in what follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Learning objectives:**\n",
    "1. Construct and manipulate BlockOperators and BlockDataContainer, including direct and adjoint operations and algebra.\n",
    "2. Use Block Framework to solve Tikhonov regularisation with CGLS algorithm.\n",
    "3. Apply Tikhonov regularisation to tomographic reconstruction and explain the effect of regularization parameter and operator in regulariser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all imports required are carried out. This included tools from the ccpi.framework and ccpi.optimisation modules, as well as test image generation tools in the tomophantom library and standard imports such as numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from ccpi.framework import ImageGeometry, ImageData \n",
    "from ccpi.framework import AcquisitionGeometry, AcquisitionData\n",
    "from ccpi.framework import BlockDataContainer\n",
    "from ccpi.framework import TestData\n",
    "\n",
    "from ccpi.optimisation.algorithms import CGLS\n",
    "from ccpi.optimisation.operators import BlockOperator, Gradient, Identity, FiniteDiff\n",
    "\n",
    "from ccpi.astra.operators import AstraProjectorSimple \n",
    "\n",
    "import tomophantom\n",
    "from tomophantom import TomoP2D\n",
    "import scipy\n",
    "import numpy as np    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilities import plotter2D\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting up the dataset - 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2D parallel beam case will be set. At first, the parameters of acquisition geometry and the image geometry are specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#set up acquisition geometry\n",
    "number_pixels_x = 1024\n",
    "number_projections = 180\n",
    "angles = np.linspace(0, np.pi, number_projections, dtype=np.float32)\n",
    "ag = AcquisitionGeometry(geom_type='parallel', dimension='2D', angles=angles, pixel_num_h=number_pixels_x)\n",
    "\n",
    "#set up image geometry\n",
    "num_voxels_xy = 1024\n",
    "ig = ImageGeometry(voxel_num_x = num_voxels_xy, voxel_num_y = num_voxels_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a the classic Shepp-Logan test image is loaded in from tomophantom, along with an analytically computed sinogram data set of it. The pixel values are rescaled for the purpose of Poisson noise simulation in a subsequent step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Load Shepp-Logan phantom \n",
    "model = 1\n",
    "path = os.path.dirname(tomophantom.__file__)\n",
    "path_library2D = os.path.join(path, \"Phantom2DLibrary.dat\")\n",
    "\n",
    "#tomophantom takes angular input in degrees\n",
    "phantom_2D = TomoP2D.Model(model, num_voxels_xy, path_library2D)\n",
    "phantom_sino = TomoP2D.ModelSino(model, num_voxels_xy, number_pixels_x, angles*180./np.pi, path_library2D)\n",
    "\n",
    "#rescale the tomophantom data, set the max absoobtion to 25%\n",
    "set_ratio_absorption = 0.25\n",
    "new_max_value = -np.log(set_ratio_absorption)\n",
    "sino_max = np.amax(phantom_sino)\n",
    "scale = new_max_value/sino_max\n",
    "\n",
    "#allocate the image data container and copy the dataset in\n",
    "#this is only used as a reference to the ground truth\n",
    "model = ig.allocate(0)\n",
    "model.fill(phantom_2D*scale)\n",
    "\n",
    "#allocate the acquisition data container and copy the sinogram in\n",
    "sinogram = ag.allocate(0)\n",
    "sinogram.fill(phantom_sino*scale)\n",
    "\n",
    "plots = [model, sinogram]\n",
    "titles = [\"Ground truth\", \"sinogram\"]\n",
    "plotter2D(plots,titles,fix_range=False, stretch_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Poisson noise is added. The severity of the noise can be adjusted by changing the background_counts variable. The simulated clean and noisy sinograms are displayed side by side as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_counts = 500 #lower counts will increase the noise\n",
    "counts = float(background_counts) * np.exp(-sinogram.as_array())\n",
    "noisy_counts = np.random.poisson(counts)\n",
    "sino_out = -np.log(noisy_counts/background_counts)\n",
    "\n",
    "sinogram_noisy = ag.allocate()\n",
    "sinogram_noisy.fill(sino_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plots = [sinogram, sinogram_noisy]\n",
    "titles = [\"sinogram\", \"sinogram noisy\"]\n",
    "plotter2D(plots,titles,fix_range=False, stretch_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"section_CGLS_simple\"></a>\n",
    "### Reconstruct using unregularised CGLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before describing Tikhonov regularization, we recall the problem solved by CGLS:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}A u - b\\end{Vmatrix}^2_2$$\n",
    "\n",
    "where,\n",
    "\n",
    "- $A$ is the projection operator\n",
    "\n",
    "- $b$ is the acquired data\n",
    "\n",
    "- $u$ is the unknown image to be determined\n",
    "\n",
    "In the solution provided by CGLS the low frequency components tend to converge faster than the high frequency components. This means we need to control the number of iterations carefully to select the optimimum solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To solve using CGLS (and Tikhonov afterwards) we define the operator A and can choose between a CPU or GPU back-end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "device = \"gpu\"\n",
    "operator = AstraProjectorSimple(ig, ag, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We define the data b to be used in CGLS, and can here choose between the clean or the noisy sinogram data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = sinogram\n",
    "#data = sinogram_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Set up the CGLS algorithm, including specifying its initial point to start from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_init = ig.allocate(0)\n",
    "cgls_simple = CGLS(x_init=x_init, operator=operator, data=data, update_objective_interval = 10)\n",
    "cgls_simple.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once set up, we can run the algorithm for a specified number of iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgls_simple.run(20, verbose = True)\n",
    "#cgls_simple.run(1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Display the resulting image from CGLS, along with its difference image with the original ground truth image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "CGLS_simple_output = cgls_simple.get_output()\n",
    "\n",
    "plots = [CGLS_simple_output, CGLS_simple_output - model]\n",
    "titles = [\"CGLS reconstruction\",\"Difference from ground truth\" ]\n",
    "plotter2D(plots,titles,fix_range=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 1:**</span> Repeat this with the noisy dataset. Remember you can change the number of iterations to run between outputs. Try to stop the algorithm before the solution starts to diverge. [go to section start](#section_CGLS_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tikhonov regularization using CGLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regularisation\n",
    "\n",
    "Noisy datasets lead to an ill-posed problem. If we try to solve these using CGLS we end up with an unstable solution. Regularisation adds information in order for us to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tikhonov regularisation\n",
    "\n",
    "We can add a regularisation term to problem solved by CGLS; this gives us the minimisation problem in the following form, which is known as Tikhonov regularization:\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}A u - b \\end{Vmatrix}^2_2 + \\alpha^2\\|Lu\\|^2_2$$\n",
    "\n",
    "where,\n",
    "\n",
    "- $A$ is the projection operator\n",
    "\n",
    "- $b$ is the acquired data\n",
    "\n",
    "- $u$ is the unknown image to be solved for\n",
    "\n",
    "- $\\alpha$ is the regularisation parameter\n",
    "\n",
    "- $L$ is a regularisation operator\n",
    "\n",
    "\n",
    "The first term measures the fidelity of the solution to the data. The second term meausures the fidelity to the prior knowledge we have imposed on the system, operator $L$. $\\alpha$ controls the trade-off between these terms. $L$ is often chosen to be a smoothing operator like the identity matrix, or a gradient operator **constrained to the squared L2-norm**.\n",
    "\n",
    "This can be re-written equivalently in the block matrix form:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\binom{A}{\\alpha L} u - \\binom{b}{0}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "With the definitions:\n",
    "\n",
    "- $\\tilde{A} = \\binom{A}{\\alpha L}$\n",
    "\n",
    "- $\\tilde{b} = \\binom{b}{0}$\n",
    "\n",
    "this can now be recognised as a least squares problem:\n",
    "\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{b}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "and being a least squares problem, it can be solved using CGLS with $\\tilde{A}$ as operator and $\\tilde{b}$ as data.\n",
    "\n",
    "**ToDo: add citation**<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Introducing the block framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can construct $\\tilde{A}$ and $\\tilde{b}$ using the BlockFramework in the CIL.\n",
    "\n",
    "$\\tilde{A}$ is a (column) BlockOperator of size 2x1.\n",
    "\n",
    "`BlockOperator(op0,op1,shape=(1,2))` results in a row block operator, which is not what we need here.\n",
    "\n",
    "\n",
    "`BlockOperator(op0,op1)`\n",
    "and\n",
    "`BlockOperator(op0,op1,shape=(2,1))` result in a column block\n",
    "\n",
    "$\\tilde{b}$ is a BlockDataContainer\n",
    "\n",
    "`BlockDataContainer(DataContainer0, DataContainer1)`\n",
    "\n",
    "where we note that for BlockDataContainers we do not need to specify a shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"section_CGLS_alpha\"></a>\n",
    "#### Reconstruct using CGLS and the identity operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest form of Tikhonov uses the identity matrix as the regularization operator. we use an identity matrix as our regularisation operator we are adding constraints on the size of the solution $u$\n",
    "\n",
    "<span style=\"color:red;font-size:larger\">**Exercise 2:**</span> Construct the BlockOperator $\\tilde{A}$ using the idenity operator. Find the value of $\\alpha$ that gives you the best solution. **ToDo high and low alpha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the operator A\n",
    "device = \"gpu\"\n",
    "A = AstraProjectorSimple(ig, ag, device)\n",
    "L = Identity(ig)\n",
    "alpha = 0.4\n",
    "\n",
    "#operator_block = BlockOperator(  )\n",
    "operator_block = BlockOperator( A, alpha * L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the data b\n",
    "data_block = BlockDataContainer(sinogram_noisy, L.range_geometry().allocate(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Run CGLS as before, but passing the BlockOperator and BlockDataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#setup CGLS with the Block Operator and Block DataContainer\n",
    "x_init = ig.allocate(0)      \n",
    "cgls_regularised = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_regularised.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "cgls_regularised.run(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#plot the results\n",
    "CGLS_regularised_output = cgls_regularised.get_output()\n",
    "\n",
    "plots = [CGLS_regularised_output, CGLS_regularised_output - model]\n",
    "titles = [\"CGLS reconstruction\",\"Difference from ground truth\" ]\n",
    "plotter2D(plots,titles,fix_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CGLS_simple_output.as_array()[512,:])\n",
    "plt.plot(CGLS_regularised_output.as_array()[512,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the BlockFramework to build a gradient operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo: moved the bulk of the detailed explanation below, but I need something more here first. Think about explanation**\n",
    "\n",
    "A gradient operator can be constructed using BlockOperators.\n",
    "\n",
    "The direct gradient operator $\\nabla$ acts on an image $u$ and returns a BlockDataContainer $\\textbf{y}$\n",
    "\n",
    "$$ \\nabla(u) = \n",
    "\\begin{bmatrix}\n",
    "   \\nabla_x\\\\\n",
    "   \\nabla_y\\\\\n",
    "\\end{bmatrix}\n",
    "*u =\n",
    "\\begin{bmatrix}\n",
    "    \\nabla_xu\\\\\n",
    "    \\nabla_yu\\\\\n",
    "\\end{bmatrix}\n",
    "=  \n",
    "\\begin{bmatrix}w_{x}\\\\w_{y}\\end{bmatrix}= \\textbf{w}$$\n",
    "\n",
    "The adjoint gradient operator $\\nabla^*$ acts on the BlockDataContainer $\\textbf{y}$ and returns an image $\\rho$\n",
    "\n",
    "$$  \\nabla^*(\\textbf w) = \n",
    "\\begin{bmatrix}\n",
    "    \\nabla^*_x &\n",
    "    \\nabla^*_y\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix}\n",
    "    w_{x}\\\\\n",
    "    w_{y}\\\\\n",
    "\\end{bmatrix} \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    \\nabla^*_x w_x + \\nabla^*_y w_y\n",
    "\\end{bmatrix} =  \\rho$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#loading a test image\n",
    "loader = TestData()\n",
    "shapes = loader.load(TestData.SHAPES)\n",
    "shapes_ig = shapes.geometry\n",
    "\n",
    "#plot ths results\n",
    "plotter2D(shapes, \"shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finite difference operator can be called from the framework. This returns the difference between each pair of pixels along one direction.\n",
    "\n",
    "We need to initialise it with the image geometry, the direction of the calculation and the boundary conditions to use.\n",
    "\n",
    "`FiniteDiff(gm_domain, direction, bnd_cond='Neumann' or 'Periodic')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the operator FiniteDiff - needs to image geometry, the direction and the boundary conditions\n",
    "fdx = FiniteDiff(shapes_ig, direction=1, bnd_cond='Neumann')\n",
    "\n",
    "#run it over the input image\n",
    "image_2D_dx = fdx.direct(shapes)\n",
    "\n",
    "#plot ths results\n",
    "plotter2D(image_2D_dx, \"dx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 3:**</span> Create a BlockOperator to containing the the finite difference operator in the $x$ and $y$ directions. Apply it to the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the x and y operators \n",
    "fdx = FiniteDiff(shapes_ig, direction=1, bnd_cond='Neumann')\n",
    "fdy = FiniteDiff(shapes_ig, direction=0, bnd_cond='Neumann')\n",
    "\n",
    "#fdx = \n",
    "#fdy = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the BlockOperator\n",
    "FD = BlockOperator(fdx, fdy)\n",
    "#FD = #BlockOperator(fdx, fdy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run it on the test image\n",
    "fd_out = FD.direct(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "plots = [fd_out.get_item(0), fd_out.get_item(1)]\n",
    "titles = [\"dx\",\"dy\" ]\n",
    "plotter2D(plots,titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A closer look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input is ImageData\n",
    "print(\"Input\")\n",
    "print(\"\\ttype:\\t\", type(shapes))\n",
    "print(\"\\tshape:\\t\", shapes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#output is BloackDataContainer\n",
    "print(\"Output\")\n",
    "print(\"\\ttype:\\t\", type(fd_out))\n",
    "print(\"\\tshape:\\t\", fd_out.shape)\n",
    "\n",
    "print(\"\\tDataContainer 0\")\n",
    "print(\"\\t\\ttype:\\t\", type(fd_out.get_item(0)))\n",
    "print(\"\\t\\tshape:\\t\", fd_out.get_item(0).shape)\n",
    "\n",
    "print(\"\\tDataContainer 1\")\n",
    "print(\"\\t\\ttype:\\t\", type(fd_out.get_item(1)))\n",
    "print(\"\\t\\tshape:\\t\", fd_out.get_item(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#split containers\n",
    "dx = fd_out.get_item(0)\n",
    "dy = fd_out.get_item(1)\n",
    "\n",
    "#calculate the squared norm of the x and y gradients\n",
    "dx2 = (dx**2).sum()\n",
    "dy2 = (dy**2).sum()\n",
    "sq_norm = dx2 + dy2\n",
    "print(sq_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#do the same thing within the blockframework\n",
    "sq_norm = fd_out.squared_norm()\n",
    "print(sq_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BlockFramework provides basic algebra between BlockDataContainers, numpy arrays, lists of numbers,  DataContainers, subclasses and scalars providing the shape of the containers are compatible\n",
    "- add\n",
    "- subtract\n",
    "- multiply\n",
    "- divide\n",
    "- power\n",
    "- squared_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 4:**</span> Run the adjoint operator. What data type does it take in and write out?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#run the adjoint method\n",
    "adjoint_output = FD.adjoint(fd_out)\n",
    "\n",
    "plotter2D(adjoint_output, \"adjoint gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A deeper look at the BlockFramework\n",
    "#### BlockDataContainer \n",
    "\n",
    "BlockDataContainer holds datacontainers as a column vector\n",
    "\n",
    "$$\\textbf{x} = \\begin{bmatrix}x_{1}\\\\ x_{2}\\end{bmatrix}$$\n",
    "\n",
    "$$\\textbf{y} = \\begin{bmatrix}y_{1}\\\\ y_{2} \\\\ y_{3}\\end{bmatrix}$$\n",
    "\n",
    "#### BlockOperator: \n",
    "\n",
    "BlockOperator is a matrix of operators.\n",
    "\n",
    "$$ K = \\begin{bmatrix}\n",
    "A_{1} & A_{2} \\\\\n",
    "A_{3} & A_{4} \\\\\n",
    "A_{5} & A_{6}\n",
    "\\end{bmatrix}_{(3,2)} *  \\quad \\underbrace{\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \n",
    "\\end{bmatrix}_{(2,1)}}_{\\textbf{x}} =  \\begin{bmatrix}\n",
    "A_{1}x_{1}  + A_{2}x_{2}\\\\\n",
    "A_{3}x_{1}  + A_{4}x_{2}\\\\\n",
    "A_{5}x_{1}  + A_{6}x_{2}\\\\\n",
    "\\end{bmatrix}_{(3,1)} =  \\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\n",
    "\\end{bmatrix}_{(3,1)} = \\textbf{y}$$\n",
    "\n",
    "Column: Share the same domains $X_{1}, X_{2}$<br>\n",
    "Rows: Share the same ranges $Y_{1}, Y_{2}, Y_{3}$\n",
    "\n",
    "$$ K : (X_{1}\\times X_{2}) \\rightarrow (Y_{1}\\times Y_{2} \\times Y_{3})$$\n",
    "\n",
    "\n",
    "$$ A_{1}, A_{3}, A_{5}: \\text{share the same domain }  X_{1}$$\n",
    "$$ A_{2}, A_{4}, A_{6}: \\text{share the same domain }  X_{2}$$\n",
    "\n",
    "$$A_{1}: X_{1} \\rightarrow Y_{1}, \\quad A_{3}: X_{1} \\rightarrow Y_{2}, \\quad  A_{5}: X_{1} \\rightarrow Y_{3}$$\n",
    "$$A_{2}: X_{2} \\rightarrow Y_{1}, \\quad A_{4}: X_{2} \\rightarrow Y_{2}, \\quad  A_{6}: X_{2} \\rightarrow Y_{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reconstruct using Tikhonov CLGS with the gradient operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Tikhonov regularisation\n",
    "\n",
    "Now go back to our Tikonov reconstruction, this time define the gradient operator as the regulariser.\n",
    "\n",
    "$${\\mathrm{argmin}}\\begin{Vmatrix}\\binom{A}{\\alpha \\nabla} u - \\binom{b}{0}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "With the definitions:\n",
    "\n",
    "- $\\tilde{A} = \\binom{A}{\\alpha \\nabla}$\n",
    "\n",
    "- $\\tilde{b} = \\binom{b}{0}$\n",
    "\n",
    "And solve using CGLS:\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{b}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "\n",
    "We'll use the framework's `Gradient()` operator - this is an optimised form of FD over the space or space+channels dimensions.\n",
    "\n",
    "\n",
    "**ToDo explain #L.range_geometry().allocate(0) explain!**\n",
    "\n",
    "\n",
    "<span style=\"color:red;font-size:larger\">**Exercise 5:**</span> Set up the BlockOperator $\\tilde{A}$ and the BlockDataContainer $\\tilde{b}$. Run Tikhonov reconstruction using gradient regularisation and find the value of $\\alpha$ that gives you the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the operator A\n",
    "device = \"gpu\"\n",
    "A = AstraProjectorSimple(ig, ag, device)\n",
    "L = Gradient(ig)\n",
    "alpha = 150\n",
    "\n",
    "operator_block = BlockOperator( A, alpha * L, shape=(2,1))\n",
    "#operator_block = BlockOperator( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#define the data b\n",
    "\n",
    "#L.range_geometry().allocate(0) explain!\n",
    "\n",
    "#data_block = BlockDataContainer()\n",
    "data_block = BlockDataContainer(sinogram_noisy, L.range_geometry().allocate(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#setup CGLS with the block operator and block data\n",
    "x_init = ig.allocate(0)      \n",
    "cgls_tikhonov = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_tikhonov.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "cgls_tikhonov.run(100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#plot the results\n",
    "CGLS_tikhonov_output = cgls_tikhonov.get_output()\n",
    "\n",
    "plots = [CGLS_tikhonov_output, CGLS_tikhonov_output - model]\n",
    "titles = [\"CGLS reconstruction\",\"Difference from ground truth\" ]\n",
    "plotter2D(plots,titles,fix_range=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the outputs of each reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the outputs of unregularise and regularised CGLS\n",
    "plots = [model, CGLS_simple_output, CGLS_regularised_output, CGLS_tikhonov_output]\n",
    "titles = [\"Ground truth\", \"CGLS simple\",\"Tikhonov with Idenity regularisation\",\"Tikhonov with gradient regularisation\" ]\n",
    "plotter2D(plots,titles,fix_range=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.as_array()[512,:])\n",
    "plt.plot(CGLS_simple_output.as_array()[512,:])\n",
    "plt.plot(CGLS_tikhonov_output.as_array()[512,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning objectives:**\n",
    "1. Construct and manipulate BlockOperators and BlockDataContainer, including direct and adjoint operations and algebra.\n",
    "2. Use Block Framework to solve Tikhonov regularisation with CGLS algorithm.\n",
    "3. Apply Tikhonov regularisation to tomographic reconstruction and explain the effect of regularisation parameter and operator in regulariser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:jj_test_cil] *",
   "language": "python",
   "name": "conda-env-jj_test_cil-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
