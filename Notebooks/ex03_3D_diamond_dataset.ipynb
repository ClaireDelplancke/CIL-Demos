{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Copyright 2019 Science Technology Facilities Council\n",
    "# Copyright 2019 University of Manchester\n",
    "#\n",
    "# This work is part of the Core Imaging Library developed by Science Technology\t\n",
    "# Facilities Council and University of Manchester\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0.txt\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# \n",
    "#========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing a dataset from DLS\n",
    "This exercise will walk you through the reconstruction of a parallel beam 3D data set from Diamond Light Source.\n",
    "\n",
    "This exercise will show  you how to read in a data set and set up the 3D acquisition and image geometry to match it. It'll introduce some tools avaliable to help you process the data.\n",
    "\n",
    "And finally we will build up a Tikhonov reconstruction on a real data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning objectives:**\n",
    "1. You will be able to read in a data set and manipulate it in to the form required for the ASTRA projectors\n",
    "2. Use CIL processors CenterOfRotation() and Resizer() to pre-process the data\n",
    "3. Apply the same reconstruction alorithms to real data that we previously have to simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all required imports are carried out. As before this includes tools from the ccpi.framework and ccpi.optimisation modules, but now we also use tools from the ccpi.processors and ccpi.io modules.\n",
    "\n",
    "The ASTRA projectors are imported from ccpi.astra.oprators and the ccpi.astra.processors modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from ccpi.framework import ImageData, ImageGeometry\n",
    "from ccpi.framework import AcquisitionGeometry, AcquisitionData\n",
    "from ccpi.framework import BlockDataContainer\n",
    "\n",
    "from ccpi.optimisation.algorithms import CGLS\n",
    "from ccpi.optimisation.operators import BlockOperator, Gradient\n",
    "\n",
    "from ccpi.processors import Resizer, CenterOfRotationFinder\n",
    "\n",
    "from ccpi.io import NEXUSDataReader\n",
    "\n",
    "from ccpi.astra.operators import AstraProjectorSimple , AstraProjector3DSimple\n",
    "from ccpi.astra.processors import FBP\n",
    "\n",
    "from utilities import islicer, link_islicer\n",
    "from utilities import plotter2D\n",
    "\n",
    "# All external imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the NEXUS data reader to read in a dataset from the Diamond Light Source. The data reader creates the AquisitionData object for you with the geometry specified in the file.\n",
    "\n",
    "CIL also provides a reader for Nikon datasets `NikonDataReader()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up a reader object pointing to the Nexus data set\n",
    "path = os.path.join(sys.prefix, 'share','ccpi','24737_fd_normalised.nxs')\n",
    "myreader = NEXUSDataReader(nexus_file=path)\n",
    "data = myreader.load_data()\n",
    "\n",
    "#Convert the data from intensity to attenuation by taking the negative log\n",
    "data.log(out=data)\n",
    "data *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NEXUSDataReader output is either an ImageData object or an AcquisitonData Object. This is decided by the fields present in the dataset.\n",
    "\n",
    "We have created an AcquisitionData object from the input file. We can see the raw data has 3-axes where 'vertical' and 'horizontal' describe the detector axes and 'angle' giving the rotation of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "print(data)\n",
    "\n",
    "islicer(data, direction=0, minmax=(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centre of Rotation\n",
    "\n",
    "The Centre of Rotation is the projection of the axis of rotation on to the detector. The reconstruction assumes this is in the centre of the detector, and it being offset introduces blurring and artefacts in the reconstruction.\n",
    "\n",
    "**ToDo: show geometry** \n",
    "\n",
    "We need to re-proccess the acquisition data to correct it for this offset.\n",
    "\n",
    "The code below reconstucts one slice of the data. By shifting the acquisition data and looking at the reconstructed slice we can get a feel for what a centre of rotation offset looks like.\n",
    "\n",
    "<span style=\"color:red;font-size:larger\">**Exercise 1:**</span> Change the value of centre of rotation offset to find the best reconstruction of this slice. What happens if you change the slice number to 80? How about 20?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists containers for the output\n",
    "title = []\n",
    "results = []\n",
    "\n",
    "#pick a slice to reconstruct\n",
    "slice_num = 67\n",
    "\n",
    "#create a new dataset that is just single slice of the data\n",
    "data_slice =  data.subset(vertical=slice_num)\n",
    "\n",
    "#convert the angles from degrees to radians for ASTRA\n",
    "data_slice.geometry.angles = data.geometry.angles * np.pi /180.\n",
    "\n",
    "# Create Acquisition Geometry\n",
    "ag = data_slice.geometry.clone()\n",
    "\n",
    "# Create Image Geometry\n",
    "ig = ImageGeometry(voxel_num_x=ag.pixel_num_h, voxel_num_y=ag.pixel_num_h )\n",
    "\n",
    "#pick some values of Centre of rotation offset to compare\n",
    "offset_list = [0,5,10]\n",
    "\n",
    "for shift in offset_list:\n",
    "   \n",
    "    #translate the acquisition data\n",
    "    data_shifted = ag.allocate()  \n",
    "    scipy.ndimage.interpolation.shift(data_slice.as_array(), (0,-shift), output = data_shifted.as_array(), order=1,mode='nearest')\n",
    "    \n",
    "    #Perform a fast reconstruction of the slice using FBP\n",
    "    fbp = FBP(ig, ag, device='gpu')\n",
    "    fbp.set_input(data_shifted)\n",
    "    FBP_output = fbp.get_output()  \n",
    "\n",
    "    title.append(\"CoR = %s pixels\" % shift)\n",
    "    results.append(FBP_output.as_array()[:,:])\n",
    "\n",
    "#plot the results    \n",
    "plotter2D(results,title,fix_range=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use processors to pre-proccess the data\n",
    "\n",
    "CIL gives you access to some commonly needed data processors including:\n",
    "- `Normalizer()` normalises AcquisitionData based on the instrument reading with and without incident photons or neutrons\n",
    "- `Resizer()` allows you to crop or bin the data in any dimension\n",
    "- `CenterOfRotationFinder()` finds the center of rotation in a parallel beam dataset (credit: Nghia Vo)\n",
    "\n",
    "The processors are called in the following way:<br>\n",
    ">processor_instance = Processor(set_up_parameters)<br>\n",
    ">processor_instance.set_input(data_in)<br>\n",
    ">data_out = processor_instance.get_output()<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use CenterOfRotationFinder()\n",
    "\n",
    "We can use `CenterOfRotationFinder()` to locate the Centre of Rotation in a parallel beam dataset. The output is in pixels at the detector.\n",
    "\n",
    "**ToDo: show diagram** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the processsor\n",
    "cor = CenterOfRotationFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the input data\n",
    "cor.set_input(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output data\n",
    "center_of_rotation = cor.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Centre of rotation at x = \", center_of_rotation)\n",
    "shift = (center_of_rotation - data.shape[2]/2)\n",
    "print(\"Centre of rotation - detector centre = \", shift, \" pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this agree with what you saw in Excercise 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can correct the acquisition data for the centre of rotation offset above. We do this using a scipy function that shifts and interpolates the data. You could also crop or pad the data to correct for the offset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocate the memory\n",
    "data_centred = data.geometry.allocate()\n",
    "#use scipy to do a translation and interpolation of each projection image\n",
    "shifted = scipy.ndimage.interpolation.shift(data.as_array(), (0,0,-shift), order=3,mode='nearest')\n",
    "data_centred.fill(shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the data set\n",
    "islicer(data_centred, direction=0, minmax=(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:larger\">**Exercise 2:**</span> Process the corrected data `data_centred` with  CentreOfRotationFinder() and convince yourself it's now close to the centre of the detector.\n",
    "\n",
    "Remember processors are used as:\n",
    ">processor_instance = Processor(set_up_parameters)<br>\n",
    ">processor_instance.set_input(data_in)<br>\n",
    ">data_out = processor_instance.get_output()<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the processsor\n",
    "\n",
    "# set the input data\n",
    "\n",
    "# get the output data\n",
    "center_of_rotation =\n",
    "\n",
    "print(\"Centre of rotation at x = \", center_of_rotation)\n",
    "shift = (center_of_rotation - data_centred.shape[2]/2)\n",
    "print(\"Centre of rotation - detector centre = \", shift, \" pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizer()\n",
    "`Resizer(roi, binning)`\n",
    "\n",
    "Resizer() is a processor used to crop or bin the data.\n",
    "\n",
    "To crop the data pass the optional region of interest parameter `roi`. This is a list where each element defines the behaviour along one dimension. To crop along an axis pass a tuple containing the start and end coordinates of the crop `roi=[-1,-1,(index0, index1)]` will crop the data between index0 and index1 in dimension 2.\n",
    "\n",
    "To bin the data in any dimension pass an optional paramer `binning`. This is a list with the number of pixels to bin in each dimension `binning = [1, 1, 2]` will bin the data in blocks of 2 in dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the region of interest\n",
    "roi_crop = [-1,  (1,data_centred.shape[1]),-1]\n",
    "bins = [1, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the processsor\n",
    "resizer = Resizer(roi=roi_crop, binning=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the input data\n",
    "resizer.set_input(data_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the output data\n",
    "data_reduced = resizer.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the acquistion geometry has also been modified\n",
    "print(data_reduced)\n",
    "slicer1 = islicer(data_centred, direction=0)\n",
    "slicer2 = islicer(data_reduced, direction=0)\n",
    "link_islicer(slicer1,slicer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the data ready for ASTRA\n",
    "\n",
    "In order to use the ASTRA projectors we need to manipulate the data in to the form the ASTRA projectors expect.\n",
    "\n",
    "In 3D geomtery we need the data in the form `['vertical','angle','horizontal']`, which doesn't match the DLS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_reduced.dimension_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `AcquisitionData.subset()` to return an ordered subset of the AcquisitionData and regenerates the geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data_reduced.subset(dimensions=['vertical','angle','horizontal'])\n",
    "print(data_reduced)\n",
    "print(data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASTRA also requires the of projection angles to be in radians. DLS strores their angular data in degrees so we need to convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the angles to radians\n",
    "if data_processed.geometry.angle_unit == 'degree':\n",
    "    data_processed.geometry.angle_unit = 'radian'\n",
    "    data_processed.geometry.angles = data_reduced.geometry.angles * np.pi /180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the acquisition data\n",
    "islicer(data_processed, direction=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the 3D reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the 3D Acquistion geometry\n",
    "In the 2D example we used:<br>\n",
    "`ag = AcquisitionGeometry(geom_type='parallel', dimension='2D', angles=angles, pixel_num_h=number_pixels_x)`<br>\n",
    "\n",
    "For 3D we need to change the dimension description to ` dimension='3D'`, and pass the number of vertical pixels as `pixel_num_v`<br>\n",
    "\n",
    "However we've been using the acquistion geometry throughout this notebook so we don't need to redefine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Acquisition Geometry\n",
    "ag = data_processed.geometry.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the 3D Image geometry\n",
    "In the 2D example we used:<br>\n",
    "`ig = ImageGeometry(voxel_num_x = num_voxels_xy, voxel_num_y = num_voxels_xy)`\n",
    "\n",
    "For a 3D reconstruction we also need to pass the number of voxels we want in the $z$-direction as `voxel_num_z`. We can also set the voxel size to be equal to the detector pixel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Image Geometry\n",
    "ig = ImageGeometry(voxel_num_x=ag.pixel_num_h,\n",
    "                   voxel_num_y=ag.pixel_num_h, \n",
    "                   voxel_num_z=ag.pixel_num_v,\n",
    "                   voxel_size_x=ag.pixel_size_h,\n",
    "                   voxel_size_y=ag.pixel_size_h,\n",
    "                   voxel_size_z=ag.pixel_size_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the projector\n",
    "\n",
    "In the 2D example we used the ASTRA projector:<br>\n",
    "`'AstraProjectorSimple(volume_geometry, sinogram_geometry, device)`\n",
    "\n",
    "Now we need to use ASTRA's 3D projector (note this projector is GPU only)<br>\n",
    "`AstraProjector3DSimple(volume_geometry, sinogram_geometry)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = AstraProjector3DSimple(ig, ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct using Filtered Back Projection\n",
    "\n",
    "Reconstruct the data set using the FBP processor from ASTRA\n",
    "\n",
    "`from ccpi.astra.processors import FBP`\n",
    "\n",
    "We Run this in the same way as the processors introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the processor\n",
    "fbp = FBP(ig, ag, device='gpu')\n",
    "#set the input\n",
    "fbp.set_input(data_processed)\n",
    "#Run the procesor\n",
    "FBP_output = fbp.get_output()\n",
    "#plot the results\n",
    "islicer(FBP_output, direction=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct using Tikhonov with gradient regularisation\n",
    "\n",
    "Now we have the acquisition data in good shape it's time to set up the reconstruction. We'll once again work through the Tikhonov example, but as we go we'll modify it to work with the 3D dataset.\n",
    "\n",
    "Recall we are solving:\n",
    "$$\\underset{u}{\\mathrm{argmin}}\\begin{Vmatrix}\\tilde{A} u - \\tilde{b}\\end{Vmatrix}^2_2$$\n",
    "\n",
    "\n",
    "\n",
    "with, $\\tilde{A} = \\binom{A}{\\alpha L}$ and, $\\tilde{b} = \\binom{b}{0}$\n",
    "\n",
    "where,\n",
    "- $u$ is the unknown image to be solved for\n",
    "\n",
    "- $A$ is the projection operator\n",
    "\n",
    "- $\\alpha$ is the regularisation parameter\n",
    "\n",
    "- $L$ is a regularisation operator\n",
    "\n",
    "- $b$ is the acquired data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the block operator $\\tilde{b}$\n",
    "\n",
    "We'll again use the `Gradient()` operator. Its domain is specified by the image geometry so the code doesn't need changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = Gradient(ig)\n",
    "\n",
    "alpha = 10\n",
    "operator_block = BlockOperator(A, alpha * L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the block data container, $\\tilde{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_data = L.range_geometry().allocate(0)\n",
    "data_block = BlockDataContainer(data_processed,zero_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CGLS as before, passing the BlockOperator and BlockDataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CGLS with the Block Operator and Block DataContainer\n",
    "x_init = ig.allocate(0)      \n",
    "cgls_tikhonov = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_tikhonov.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the algorithm\n",
    "cgls_tikhonov.run(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results as a stack of 2D slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CGLS_tikhonov_output = cgls_tikhonov.get_output()\n",
    "\n",
    "islicer(CGLS_tikhonov_output, direction=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the outputs\n",
    "clim_range=(0,0.006)\n",
    "slicer1=islicer(CGLS_tikhonov_output, direction=0,minmax=clim_range,title='CGLS')\n",
    "slicer2=islicer(FBP_output, direction=0,minmax=clim_range,title='FBP')\n",
    "\n",
    "link_islicer(slicer1,slicer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the outputs\n",
    "clim_range=(0,0.11)\n",
    "slicer1=islicer(CGLS_tikhonov_output, direction=0,minmax=clim_range,title='CGLS')\n",
    "slicer2=islicer(FBP_output, direction=0,minmax=clim_range,title='FBP')\n",
    "\n",
    "link_islicer(slicer1,slicer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cil_19.07] *",
   "language": "python",
   "name": "conda-env-.conda-cil_19.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
