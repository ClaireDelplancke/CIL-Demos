{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Copyright 2019 Science Technology Facilities Council\n",
    "# Copyright 2019 University of Manchester\n",
    "#\n",
    "# This work is part of the Core Imaging Library developed by Science Technology\t\n",
    "# Facilities Council and University of Manchester\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0.txt\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# \n",
    "#========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing a dataset from DLS\n",
    "This exercise will walk you through the reconstruction of a parallel beam 3D data set from Diamond Light Source. We'll follow from the previous 2D exercises to set up and use a 3D geomety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning objectives:**\n",
    "1. Use CIL processors CentreOfTotation and Resizer to preprocess the data\n",
    "2. Change the geometry to 3D\n",
    "3. Apply the same reconstruction alorithms to real data\n",
    "\n",
    "**ToDo: reading in a dataset and manpulating the data in to the expected form**\n",
    "**ToDo: right out new data??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from ccpi.framework import ImageData, ImageGeometry\n",
    "from ccpi.framework import AcquisitionGeometry, AcquisitionData\n",
    "\n",
    "from ccpi.optimisation.algorithms import CGLS, SIRT\n",
    "from ccpi.optimisation.functions import Norm2Sq, L1Norm\n",
    "from ccpi.optimisation.operators import BlockOperator, Gradient, Identity\n",
    "from ccpi.framework import BlockDataContainer\n",
    "\n",
    "from ccpi.processors import Resizer, CenterOfRotationFinder\n",
    "\n",
    "from ccpi.io import NEXUSDataReader\n",
    "from ccpi.astra.operators import AstraProjectorSimple , AstraProjector3DSimple\n",
    "from ccpi.astra.processors import FBP\n",
    "\n",
    "# All external imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "from utilities import islicer, link_islicer\n",
    "from utilities import plotter2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the NEXUS data reader to read in a dataset from the Diamond Light Source. The data reader creates the AquisitionData object for you with the geometry specified in the file.\n",
    "\n",
    "CIL also provides a reader for Nikon datasets `NikonDataReader()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up a reader object pointing to the Nexus data set\n",
    "path = os.path.join(sys.prefix, 'share','ccpi','24737_fd_normalised.nxs')\n",
    "myreader = NEXUSDataReader(nexus_file=path)\n",
    "data = myreader.load_data()\n",
    "\n",
    "data.fill(np.random.poisson(500*data.as_array())/500)\n",
    "\n",
    "#Convert the data from intensity to attenuation by taking the negative log\n",
    "data.log(out=data)\n",
    "data *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NEXUSDataReader output is either an ImageData object or an AcquisitonData Object. This is decided by the fields present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created an AcquisitionData object from the input file. We can see the raw data has 3-axes where 'vertical' and 'horizontal' describe the output of the detector, with 'angle' giving the rotation of the object.\n",
    "\n",
    "We can look closer at the data we have read in, and have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.geometry)\n",
    "\n",
    "islicer(data, direction=0, minmax=(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centre of Rotation\n",
    "\n",
    "The Centre of Rotation is the projection of the rotate axis on to the detector. The reconstruction assumes this is in the centre of the detector, and it being offset introduces blutting and artefacts.\n",
    "\n",
    "**ToDo: show geometry** \n",
    "\n",
    "We need to reproccess the data by either padding or cropping the projections to achieve this.\n",
    "\n",
    "The code below reconstucts one slice of the data. **ToDo Exercise change range to find the best looking reconstruction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "results = []\n",
    "\n",
    "slice_num = 68\n",
    "data_transposed =  data.subset(dimensions=['vertical','angle','horizontal']).subset(vertical=slice_num)\n",
    "data_transposed.geometry.angles = data.geometry.angles * np.pi /180.\n",
    "\n",
    "# Create Acquisition Geometry\n",
    "ag = data_transposed.geometry.clone()\n",
    "\n",
    "# Create Image Geometry\n",
    "ig = ImageGeometry(voxel_num_x=ag.pixel_num_h,\n",
    "                   voxel_num_y=ag.pixel_num_h, \n",
    "                   voxel_num_z= 1 )\n",
    "\n",
    "start = 4\n",
    "step = 1\n",
    "\n",
    "for n in range(0,6):\n",
    "    shift = start + n * step  \n",
    "    data_cor = ag.allocate()\n",
    "    \n",
    "    scipy.ndimage.interpolation.shift(data_transposed.as_array(), (0,-shift), output = data_cor.as_array(), order=1,mode='nearest')\n",
    "    \n",
    "    #Initialise the processor\n",
    "    fbp = FBP(ig, ag, device='gpu')\n",
    "    fbp.set_input(data_cor)\n",
    "    FBP_output = fbp.get_output()  \n",
    "\n",
    "    title.append(\"CoR = %s pixels\" % shift)\n",
    "    results.append(FBP_output.as_array()[:,:])\n",
    "\n",
    "plotter2D(results,title,fix_range=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use processors to pre-proccess the data\n",
    "\n",
    "CIL gives you access to some commonly needed data processors including:\n",
    "- `Normalizer()` normalises AcquisitionData based on the instrument reading with and without incident photons or neutrons\n",
    "- `Resizer()` allows you to crop or bin the data in any dimension\n",
    "- `CenterOfRotationFinder()` finds the center of rotation in a parallel beam dataset (credit: Nghia Vo)\n",
    "\n",
    "The processors are called in the following way:<br>\n",
    ">processor_instance = Processor(set_up_parameters)<br>\n",
    ">processor_instance.set_input(data_in)<br>\n",
    ">data_out = processor_instance.get_output()<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use CenterOfRotationFinder()\n",
    "\n",
    "We can use `CentreOfRotationFinder()` to locate the Centre of Rotation in a parallel beam dataset. The output is in pixels at the detector.\n",
    "\n",
    "**ToDo: show diagram** \n",
    "\n",
    "**ToDo: fix CoR to work on transposed data**\n",
    "\n",
    "**ToDo: exercise??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the processsor\n",
    "cor = CenterOfRotationFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the input data\n",
    "cor.set_input(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output data\n",
    "center_of_rotation = cor.get_output()\n",
    "print(\"Centre of rotation at x = \", center_of_rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = (center_of_rotation - data.shape[2]/2)\n",
    "print(\"Centre of rotation - detector centre = \", shift, \" pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this agree with the reconstructions above? **ToDo: link**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct the acquisition data for the centre of rotation offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocate the memory\n",
    "data_centred = data.geometry.allocate()\n",
    "\n",
    "#shift = 0\n",
    "#use scipy to do a translation and interpolation of each projection image\n",
    "shifted = scipy.ndimage.interpolation.shift(data.as_array(), (0,0,-shift), order=1,mode='nearest')\n",
    "data_centred.fill(shifted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(data_centred, direction=0, minmax=(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo: exercise??**\n",
    "Run the CentreOfRotationFinder() over the centred data set and convince yourself it's now close to the centre of the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the processsor\n",
    "cor = CenterOfRotationFinder()\n",
    "\n",
    "# set the input data\n",
    "cor.set_input(data_centred)\n",
    "\n",
    "# get the output data\n",
    "center_of_rotation = cor.get_output()\n",
    "\n",
    "print(\"Centre of rotation at x = \", center_of_rotation)\n",
    "shift = (center_of_rotation - data.shape[2]/2)\n",
    "print(\"Centre of rotation - detector centre = \", shift, \" pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Resizer()\n",
    "`Resizer(roi, binning)`\n",
    "\n",
    "To crop the data pass the optional parameter `roi` (region of interest). This is passed as a list where each element defines the behaviour in one dimension. To crop along an axis pass a tuple of the start and end coordinates of the crop, otherwise pass -1.\n",
    "\n",
    "To bin the data in any dimension pass an optional paramer `binning`. This is a list with the number of pixels to bin in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the region of interest\n",
    "roi_crop = [-1,-1,-1]\n",
    "bins = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the processsor\n",
    "resizer = Resizer(roi=roi_crop, binning=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the input data\n",
    "resizer.set_input(data_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the output data\n",
    "data_reduced = resizer.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the acquistion geometry has also been modified\n",
    "print(data_reduced)\n",
    "islicer(data_centred, direction=0)\n",
    "islicer(data_reduced, direction=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the data ready for ASTRA\n",
    "\n",
    "**ToDo: Data sets come in different forms so we need to make some changes before reconstruction** \n",
    "\n",
    "ASTRA expects the data in the order `['vertical','angle','horizontal']` so we need to transpose the dataset.\n",
    "\n",
    "We can use `AcquisitionData.subset()` which returns a subset of the AcquisitionData and regenerates the geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data_reduced.subset(dimensions=['vertical','angle','horizontal'])\n",
    "print(data_reduced)\n",
    "print(data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASTRA also requires the of projection angles to be in radians. Diamond outputs them in degrees so we need to convert them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the angles to radians\n",
    "if data_processed.geometry.angle_unit == 'degree':\n",
    "    data_processed.geometry.angle_unit = 'radian'\n",
    "    data_processed.geometry.angles = data_reduced.geometry.angles * np.pi /180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the acquisition data\n",
    "islicer(data_processed, direction=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Geometry\n",
    "\n",
    "**ToDo: add geometry diagrame here**\n",
    "\n",
    "#### Acquistion geometry\n",
    "In the 2D example we used:<br>\n",
    "`ag = AcquisitionGeometry(geom_type='parallel', dimension='2D', angles=angles, pixel_num_h=number_pixels_x)`<br>\n",
    "\n",
    "For 3D we need to change the dimension description to ` dimension='3D'`, and pass the number of vertical pixels as `pixel_num_v`<br>\n",
    "\n",
    "However we've been using the acquistion geometry throughout this notebook so let's just clone the version we've already set up.\n",
    "\n",
    "#### Image geometry\n",
    "In the 2D example we used:<br>\n",
    "`ig = ImageGeometry(voxel_num_x = num_voxels_xy, voxel_num_y = num_voxels_xy)`\n",
    "\n",
    "For ad 3D reconstruction we also need to pass the number of voxels we want in the $z$-direction as `voxel_num_z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Acquisition Geometry\n",
    "ag = data_processed.geometry.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Image Geometry\n",
    "ig = ImageGeometry(voxel_num_x=ag.pixel_num_h,\n",
    "                   voxel_num_y=ag.pixel_num_h, \n",
    "                   voxel_num_z=ag.pixel_num_v,\n",
    "                   voxel_size_x=ag.pixel_size_h,\n",
    "                   voxel_size_y=ag.pixel_size_h,\n",
    "                   voxel_size_z=ag.pixel_size_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBP Reconstruction\n",
    "\n",
    "Reconstruct the data set using the FBP processor from ASTRA\n",
    "\n",
    "`from ccpi.astra.processors import FBP`\n",
    "\n",
    "We Run this in the same way as the processors introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the processor\n",
    "fbp = FBP(ig, ag, device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the input\n",
    "fbp.set_input(data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the procesor\n",
    "FBP_output = fbp.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "islicer(FBP_output, direction=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the projector\n",
    "\n",
    "In the 2D example we used the 2D projector from ASTRA<br>\n",
    "`'AstraProjectorSimple(volume_geometry, sinogram_geometry, device)`\n",
    "\n",
    "Use ASTRA's 3D projector, note this projector is GPU only<br>\n",
    "`AstraProjector3DSimple(volume_geometry, sinogram_geometry)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the projector object\n",
    "print (\"Define projector\")\n",
    "Cop = AstraProjector3DSimple(ig, ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SIRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup SIRT\n",
    "x_init = ig.allocate(0)\n",
    "sirt = SIRT(x_init=x_init, operator=Cop, data=data_processed, update_objective_interval = 10)\n",
    "sirt.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "sirt.run(100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "SIRT_output = sirt.get_output()\n",
    "islicer(SIRT_output, direction=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tikhonov CGLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the operator\n",
    "alpha = 20\n",
    "L = Gradient(ig)\n",
    "operator_block = BlockOperator( Cop, alpha * L, shape=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the data b\n",
    "data_block = BlockDataContainer(data_processed, L.range_geometry().allocate(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Tikonov\n",
    "x_init = ig.allocate(0)\n",
    "cgls_tikhonov = CGLS(x_init=x_init, operator=operator_block, data=data_block, update_objective_interval = 10)\n",
    "cgls_tikhonov.max_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "cgls_tikhonov.run(100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "CGLS_tikhonov_output = cgls_tikhonov.get_output()\n",
    "\n",
    "islicer(CGLS_tikhonov_output, direction=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the outputs\n",
    "clim_range=(0,0.006)\n",
    "slicer1=islicer(SIRT_output, direction=0,minmax=clim_range,title='SIRT')\n",
    "slicer2=islicer(CGLS_tikhonov_output, direction=0,minmax=clim_range,title='CGLS')\n",
    "slicer3=islicer(FBP_output, direction=0,minmax=clim_range,title='FBP')\n",
    "\n",
    "link_islicer(slicer1,slicer2,slicer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the outputs\n",
    "clim_range=(0,0.11)\n",
    "slicer1=islicer(SIRT_output, direction=0,minmax=clim_range,title='SIRT')\n",
    "slicer2=islicer(CGLS_tikhonov_output, direction=0,minmax=clim_range,title='CGLS')\n",
    "slicer3=islicer(FBP_output, direction=0,minmax=clim_range,title='FBP')\n",
    "\n",
    "link_islicer(slicer1,slicer2,slicer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cil_19.07] *",
   "language": "python",
   "name": "conda-env-.conda-cil_19.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
